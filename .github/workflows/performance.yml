name: âš¡ Performance Testing

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to test'
        required: true
        type: choice
        options:
          - staging
          - production
      duration:
        description: 'Test duration (e.g., 5m, 10m)'
        required: true
        default: '5m'
      concurrent_users:
        description: 'Number of concurrent users'
        required: true
        default: '50'
        type: number

jobs:
  performance-test:
    name: âš¡ Run Performance Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: ðŸ“¥ Checkout
        uses: actions/checkout@v4
        
      - name: ðŸ³ Setup K6
        run: |
          sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: âš¡ Run Load Test
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          DURATION="${{ github.event.inputs.duration }}"
          USERS="${{ github.event.inputs.concurrent_users }}"
          
          if [[ "$ENVIRONMENT" == "production" ]]; then
            BASE_URL="https://api.spacelaunchnow.app"
          else
            BASE_URL="https://staging.spacelaunchnow.app"
          fi
          
          # Create K6 test script
          cat > performance-test.js << EOF
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          import { Rate } from 'k6/metrics';
          
          export let errorRate = new Rate('errors');
          
          export let options = {
            stages: [
              { duration: '2m', target: $USERS }, // Ramp up
              { duration: '$DURATION', target: $USERS }, // Stay at load
              { duration: '2m', target: 0 }, // Ramp down
            ],
            thresholds: {
              http_req_duration: ['p(95)<500'], // 95% of requests must complete below 500ms
              errors: ['rate<0.1'], // Error rate must be below 10%
            },
          };
          
          export default function() {
            // Test main API endpoints
            let endpoints = [
              '/api/2.2.0/launch/',
              '/api/2.2.0/launch/upcoming/',
              '/api/2.2.0/events/',
              '/api/2.2.0/agencies/',
            ];
            
            let endpoint = endpoints[Math.floor(Math.random() * endpoints.length)];
            let response = http.get('$BASE_URL' + endpoint);
            
            let success = check(response, {
              'status is 200': (r) => r.status === 200,
              'response time < 500ms': (r) => r.timings.duration < 500,
              'response has data': (r) => r.body.includes('results'),
            });
            
            errorRate.add(!success);
            sleep(1);
          }
          EOF
          
          # Run the test
          k6 run --out json=results.json performance-test.js
          
      - name: ðŸ“Š Process Results
        run: |
          # Extract key metrics from results
          cat results.json | jq -r 'select(.type=="Point" and .metric=="http_req_duration") | .data.value' | \
            awk '{sum+=$1; count++} END {print "Average Response Time: " sum/count "ms"}' > metrics.txt
          
          cat results.json | jq -r 'select(.type=="Point" and .metric=="http_reqs") | .data.value' | \
            tail -1 | awk '{print "Total Requests: " $1}' >> metrics.txt
          
          ERROR_RATE=$(cat results.json | jq -r 'select(.type=="Point" and .metric=="errors") | .data.value' | tail -1)
          echo "Error Rate: ${ERROR_RATE}%" >> metrics.txt
          
          echo "ðŸ“Š Performance Test Results:"
          cat metrics.txt
          
      - name: ðŸ“ˆ Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: performance-results-${{ github.event.inputs.environment }}-${{ github.run_number }}
          path: |
            results.json
            metrics.txt
            
      - name: ðŸ“¢ Notify Results
        uses: Ilshidur/action-discord@master
        env:
          DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}
        with:
          args: |
            âš¡ **Performance Test Completed**
            
            **Environment:** ${{ github.event.inputs.environment }}
            **Duration:** ${{ github.event.inputs.duration }}
            **Concurrent Users:** ${{ github.event.inputs.concurrent_users }}
            
            ðŸ“Š **Results:**
            $(cat metrics.txt)
            
            ðŸ”— **Details:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
